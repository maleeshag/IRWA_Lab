# -*- coding: utf-8 -*-
"""Lab_05_IRWA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZLrwZNjV9-IVEhDlHgrQbdLkmRZnYRAY
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import word_tokenize
import numpy as np

import nltk
nltk.download('punkt')

#Index Elimination
documents=[
    "This is document 1. It contains some text for testing.",
    "Document 2 has different content for testing purposes.",
    "The third document is here with unique words.",

]
query="This is a test query for information retrieval."

query1=query.lower()
docukent1=[doc.lower() for doc in documents]

tfidf=TfidfVectorizer()

document1=[doc.lower() for  doc in documents]

doc_tfidf=tfidf.fit_transform(document1)
query_tfidf=tfidf.transform([query1])

qt=word_tokenize(query1)

champ={}

#list(enumerate(query1))
for i, term in enumerate(qt):
  doc_terms=doc_tfidf[:,i].toarray().flatten()
  max_docs=list(reversed(np.argsort(doc_terms)))[:2]

  champ[term]=max_docs

champ

qs=set(word_tokenize(query.lower()))

ds=[set(word_tokenize(doc.lower())) for doc in documents]

ds

jscores=[len(qs.intersection(s))/len(qs.union(s)) for s in ds]

jscores

z=zip(documents,jscores)

[i for i,j in z if j>=0.2]

query1=query.lower()

document1=[doc.lower() for  doc in documents]

tfidf=TfidfVectorizer()#vecs mean  object

doc_tfidf=tfidf.fit_transform(document1)
doc_tfidf

query_tfidf=tfidf.transform([query1])

query_tfidf.toarray()[0]

min_tfidf=0.6

tfidf.get_feature_names_out()#this values get above array
#tfidf.get_feature_names()

z=zip(tfidf.get_feature_names_out(),query_tfidf.toarray()[0])

[i for i,j in z if j>=min_tfidf]