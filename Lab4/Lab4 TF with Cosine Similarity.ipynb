{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1581fb0",
   "metadata": {},
   "source": [
    "# 1.Term Frequency(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7d7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aa4f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents\n",
    "doc1=\"I want to start learning to charge something in life\"\n",
    "doc2=\"reading something about life no one else knows\"\n",
    "doc3=\"Never stop learning\"\n",
    "#query striing\n",
    "query=\"life learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbd778f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preprocessing steps are ignored as the objective of this kernal is to expalin and develop TF-IDF and cosine similarity from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "399f7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Document  want  life  I  in  something  charge  start  to  learning\n",
      "0  Term Frequency     1     1  1   1          1       1      1   2         1\n",
      "         Document  about  life  no  one  else  something  reading  knows\n",
      "0  Term Frequency      1     1   1    1     1          1        1      1\n",
      "         Document  stop  Never  learning\n",
      "0  Term Frequency     1      1         1\n"
     ]
    }
   ],
   "source": [
    "#term - frequency : word occurences in a document\n",
    "\n",
    "def compute_tf(docs_list):\n",
    "    for doc in docs_list:\n",
    "        doc1_lst=doc.split(\" \")\n",
    "        \n",
    "        wordDict_1=dict.fromkeys(set(doc1_lst),0)\n",
    "        \n",
    "        for token in doc1_lst:\n",
    "            wordDict_1[token]+=1\n",
    "        df=pd.DataFrame([wordDict_1])\n",
    "        idx=0\n",
    "        \n",
    "        new_col=[\"Term Frequency\"]\n",
    "        \n",
    "        df.insert(loc=idx,column=\"Document\",value=new_col)\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "\n",
    "compute_tf([doc1,doc2,doc3])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ab5f9",
   "metadata": {},
   "source": [
    "in reality each document will be of different size. On a large document the frequency of the terms will be much higher than the smaller ones . Hence we need to normaluze the document based on its size\n",
    "\n",
    "A simple  trick is to divide the term frequency by the total number of terms \n",
    "\n",
    "for example in document 1 the term \"game\" occures 2 times. the total number of terms in the document is 10. Hence the normalized term frequency is 2/10=0.2\n",
    "\n",
    "\n",
    "Given below are the normalized term frequency for all documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27df103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Document  want  life    I   in  something  charge  start   to  \\\n",
      "0  Normallized TF   0.1   0.1  0.1  0.1        0.1     0.1    0.1  0.2   \n",
      "\n",
      "   learning  \n",
      "0       0.1  \n",
      "         Document  about   life     no    one   else  something  reading  \\\n",
      "0  Normallized TF  0.125  0.125  0.125  0.125  0.125      0.125    0.125   \n",
      "\n",
      "   knows  \n",
      "0  0.125  \n",
      "         Document      stop     Never  learning\n",
      "0  Normallized TF  0.333333  0.333333  0.333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'want': 0.1,\n",
       "  'life': 0.1,\n",
       "  'I': 0.1,\n",
       "  'in': 0.1,\n",
       "  'something': 0.1,\n",
       "  'charge': 0.1,\n",
       "  'start': 0.1,\n",
       "  'to': 0.2,\n",
       "  'learning': 0.1},\n",
       " {'about': 0.125,\n",
       "  'life': 0.125,\n",
       "  'no': 0.125,\n",
       "  'one': 0.125,\n",
       "  'else': 0.125,\n",
       "  'something': 0.125,\n",
       "  'reading': 0.125,\n",
       "  'knows': 0.125},\n",
       " {'stop': 0.3333333333333333,\n",
       "  'Never': 0.3333333333333333,\n",
       "  'learning': 0.3333333333333333}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalized term frequency\n",
    "def termFrequency(term,document):\n",
    "    normalizeDocumnet =document.lower().split()\n",
    "    return normalizeDocumnet.count(term.lower())/float(len(normalizeDocumnet))\n",
    "    \n",
    "    \n",
    "    \n",
    "def compute_normalizedTF(documents):\n",
    "    tf_doc=[]\n",
    "    \n",
    "    for txt in documents:\n",
    "        sentence =txt.split()\n",
    "        norm_tf=dict.fromkeys(set(sentence),0)\n",
    "        \n",
    "        for word in sentence:\n",
    "            norm_tf[word]=termFrequency(word,txt)\n",
    "            \n",
    "        tf_doc.append(norm_tf)\n",
    "        \n",
    "        df=pd.DataFrame([norm_tf])\n",
    "        \n",
    "        idx=0\n",
    "        new_col=[\"Normallized TF\"]\n",
    "        \n",
    "        df.insert(loc=idx,column=\"Document\",value=new_col)\n",
    "        print(df)\n",
    "        \n",
    "    return tf_doc\n",
    "\n",
    "tf_doc=compute_normalizedTF([doc1,doc2,doc3])\n",
    "tf_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6afe2c",
   "metadata": {},
   "source": [
    "# 2) IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c3bdccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 2.09861228866811,\n",
       " 'want': 2.09861228866811,\n",
       " 'to': 2.09861228866811,\n",
       " 'start': 2.09861228866811,\n",
       " 'learning': 1.4054651081081644,\n",
       " 'charge': 2.09861228866811,\n",
       " 'something': 1.4054651081081644,\n",
       " 'in': 2.09861228866811,\n",
       " 'life': 1.4054651081081644,\n",
       " 'reading': 2.09861228866811,\n",
       " 'about': 2.09861228866811,\n",
       " 'no': 2.09861228866811,\n",
       " 'one': 2.09861228866811,\n",
       " 'else': 2.09861228866811,\n",
       " 'knows': 2.09861228866811,\n",
       " 'Never': 2.09861228866811,\n",
       " 'stop': 2.09861228866811}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IDF(term,allDocuments):\n",
    "    numDocumentsWithThisTerm=0\n",
    "    \n",
    "    for doc in range (0,len(allDocuments)):\n",
    "        if term.lower() in allDocuments[doc].lower().split():\n",
    "            numDocumentsWithThisTerm=numDocumentsWithThisTerm+1\n",
    "            \n",
    "    \n",
    "    if numDocumentsWithThisTerm>0:\n",
    "        return 1.0+math.log(float(len(allDocuments))/numDocumentsWithThisTerm)\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "    \n",
    "    \n",
    "def compute_idf(documents):\n",
    "    idf_dict={}\n",
    "    for doc in documents :\n",
    "        sentence=doc.split()\n",
    "        for word in sentence:\n",
    "            idf_dict[word]=IDF(word,documents)\n",
    "            \n",
    "    return idf_dict\n",
    "\n",
    "\n",
    "idf_dict = compute_idf([doc1,doc2,doc3])\n",
    "\n",
    "compute_idf([doc1,doc2,doc3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283cdfde",
   "metadata": {},
   "source": [
    "# 3) TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4dfde",
   "metadata": {},
   "source": [
    "Remember we are trying to find out relevant documents for the query \"life learning\"\n",
    "\n",
    "for each term in the query multiply its normalized term frequency with its IDF on each document\n",
    "\n",
    "in document1 for the term \"life \" the normalized term frequency is 0.1 and its IDF is 1.4054651081081644\n",
    "\n",
    "Multiplying them together we get (0.1 * 1.4054651081081644)\n",
    "\n",
    "Given below is TF * IDF calculations for \"life\" and \"learning\" in all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db2b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc ID      life  learning\n",
      "0     0.0  0.140547  0.140547\n",
      "1     1.0  0.175683  0.000000\n",
      "2     2.0  0.000000  0.468488\n"
     ]
    }
   ],
   "source": [
    "#tf-idf score across all docs for the query string (\"life learning\")\n",
    "def compute_tfidf_with_alldocs(documents,query):\n",
    "    tf_idf=[]\n",
    "    index=0\n",
    "    \n",
    "    query_tokens=query=query.split()\n",
    "    df=pd.DataFrame(columns=[\"doc ID\"]+query_tokens)\n",
    "    \n",
    "    for doc in documents:\n",
    "        df[\"doc ID\"]=np.arange(0,len(documents))\n",
    "        doc_num=tf_doc[index]\n",
    "        \n",
    "        sentence=doc.split()\n",
    "        \n",
    "        for word in sentence:\n",
    "            for text in query_tokens:\n",
    "                if(text==word):\n",
    "                    idx=sentence.index(word)\n",
    "                    tf_idf_score=doc_num[word]*idf_dict[word]\n",
    "                    tf_idf.append(tf_idf_score)\n",
    "                    df.iloc[index,df.columns.get_loc(word)]=tf_idf_score\n",
    "                    \n",
    "        index+=1\n",
    "        \n",
    "    df.fillna(0,axis=1,inplace=True)\n",
    "    \n",
    "    return tf_idf,df\n",
    "\n",
    "\n",
    "\n",
    "documents=[doc1,doc2,doc3]\n",
    "tf_idf,df=compute_tfidf_with_alldocs(documents,query)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecaf7b",
   "metadata": {},
   "source": [
    "# 4) Vector space models and representation - cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dddfbfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'life': 0.5, 'learning': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#normalized TF for the query string (\"life learning\")\n",
    "def compute_query_tf(query):\n",
    "    query_norm_tf={}\n",
    "    tokens=query.split()\n",
    "    for word in tokens:\n",
    "        query_norm_tf[word]=termFrequency(word,query)\n",
    "    return query_norm_tf\n",
    "\n",
    "query_norm_tf=compute_query_tf(query)\n",
    "print(query_norm_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97a2c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'life': 1.4054651081081644, 'learning': 1.4054651081081644}\n"
     ]
    }
   ],
   "source": [
    "#idf score for the query string(\"life learning\")\n",
    "def compute_query_idf(query):\n",
    "    idf_dict_qry={}\n",
    "    sentence = query.split()\n",
    "    documents=[doc1,doc2,doc3]\n",
    "    \n",
    "    for word in sentence:\n",
    "        idf_dict_qry[word]=IDF(word,documents)\n",
    "        \n",
    "    return idf_dict_qry\n",
    "\n",
    "idf_dict_qry = compute_query_idf(query)\n",
    "print(idf_dict_qry)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16926b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'life': 0.7027325540540822, 'learning': 0.7027325540540822}\n"
     ]
    }
   ],
   "source": [
    "#tf-idf score for the query string (\"life learning\")\n",
    "def compute_query_tfidf(query):\n",
    "    tfidf_dict_qry={}\n",
    "    sentence=query.split()\n",
    "    \n",
    "    for word in sentence:\n",
    "        tfidf_dict_qry[word]=query_norm_tf[word] * idf_dict_qry[word]\n",
    "    return tfidf_dict_qry\n",
    "\n",
    "tfidf_dict_qry=compute_query_tfidf(query)\n",
    "\n",
    "print(tfidf_dict_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0c436f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(tfidf_dict_qry,df,query,doc_num):\n",
    "    \n",
    "    dot_product=0\n",
    "    qry_mod=0\n",
    "    doc_mod=0\n",
    "    tokens=query.split()\n",
    "    \n",
    "    for keyword in tokens:\n",
    "        dot_product+=tfidf_dict_qry[keyword] * df[keyword][df['doc ID'] ==doc_num]\n",
    "        \n",
    "        #||Query||\n",
    "        qry_mod+=tfidf_dict_qry[keyword] * tfidf_dict_qry[keyword]\n",
    "        \n",
    "        #||Document||\n",
    "        doc_mod+=df[keyword][df['doc ID']==doc_num] * df[keyword][df['doc ID']==doc_num]\n",
    "        \n",
    "    qry_mod = np.sqrt(qry_mod)\n",
    "    doc_mod=np.sqrt(doc_mod)\n",
    "    \n",
    "    #implement formular\n",
    "    denominator = qry_mod * doc_mod\n",
    "    cos_sin = dot_product/denominator\n",
    "    \n",
    "    return cos_sin\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92e6b1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.707107\n",
       "Name: life, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidf_dict_qry,df,query,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19bda2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a97edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lis):\n",
    "    for item in lis:\n",
    "        if isinstance(item,Iterable) and not isinstance(item,str):\n",
    "            for x in flatten(item):\n",
    "                yield x\n",
    "                \n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd988bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document1', 'Document2', 'Document3']\n",
      "[1.0, 0.7071067811865475, 0.7071067811865475]\n"
     ]
    }
   ],
   "source": [
    "def rank_similarity_docs(data):\n",
    "    cos_sin = []\n",
    "    for doc_num in range(0,len(data)):\n",
    "        cos_sin.append(cosine_similarity(tfidf_dict_qry,df,query,doc_num).tolist())\n",
    "        \n",
    "    return cos_sin\n",
    "\n",
    "similarity_docs=rank_similarity_docs(documents)\n",
    "\n",
    "doc_names=[\"Document1\",\"Document2\",\"Document3\"]\n",
    "\n",
    "print(doc_names)\n",
    "print(list(flatten(similarity_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f5d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de467e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
