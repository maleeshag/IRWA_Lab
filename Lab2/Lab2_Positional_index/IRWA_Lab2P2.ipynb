{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 03\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bbGYfhnaIYx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code essentially reads and processes multiple documents, normalizes the text, removes stopwords, performs stemming, and constructs an inverted index with positional information for each term in the documents."
      ],
      "metadata": {
        "id": "iXuxCh64LgGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries: The code begins by importing required libraries such as drive from google.colab, re for regular expressions, defaultdict from collections, PorterStemmer from nltk.stem, stopwords and word_tokenize from nltk, and os for operating system-related operations."
      ],
      "metadata": {
        "id": "zZHA4WwIJmbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import re   #regular expressions - regettes\n",
        "from collections import defaultdict\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os"
      ],
      "metadata": {
        "id": "MiukxjkQQLXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b05dZGJKRBmg",
        "outputId": "36526e25-d81b-45b1-f93a-3faee0e4396e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Google Drive: The code mounts the Google Drive using the drive.mount() function. This step is specific to Google Colab and allows access to files stored in Google Drive."
      ],
      "metadata": {
        "id": "Osxp-xP-Jp-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0jy5fJLRScu",
        "outputId": "0d0f1b02-225a-424c-c202-ef784443511e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the current directory: The code changes the current directory to the specified path in Google Drive using the %cd magic command. This step is also specific to Google Colab and sets the working directory for the subsequent file operations."
      ],
      "metadata": {
        "id": "LIGw8WetNbYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/IRWA_lab/positional/"
      ],
      "metadata": {
        "id": "prYF3nJgRbZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478f1d46-0b2d-4822-e03e-a3689557b585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA_lab/positional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing dictionaries: The code creates two dictionaries, dictionary and documents, to store the inverted index and document information, respectively."
      ],
      "metadata": {
        "id": "kOL1nd1MNkrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary=dict()\n",
        "documents=dict()\n"
      ],
      "metadata": {
        "id": "54uod0XDNk3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlxSt8FnZon8",
        "outputId": "8ad8b5c8-cfb0-476f-940f-9e228d17b9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cwd=os.getcwd()\n",
        "cwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5On8JXV9OEWm",
        "outputId": "340b467b-3622-43a3-9d45-097b11b5873f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IRWA_lab/positional'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing each document: The code loops over each document, from 1 to 3, and performs the following operations:"
      ],
      "metadata": {
        "id": "3veNWuYCOt9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for doc_no in range(1,4):\n",
        "  # Reading the document: It reads the contents of the document file (doc_1.txt, doc_2.txt, etc.) using the open() function and stores the content in the variable s. The contents are read\n",
        "  # as a single line and any newline characters are replaced with a space.\n",
        "\n",
        "  with open (cwd+'/doc_'+str(doc_no)+\".txt\",'r') as file:\n",
        "     s=file.read().replace('\\n',' ')\n",
        "\n",
        "  #normalizing\n",
        "  #replacing the unnessary characters( won't - > will not )\n",
        "  # Normalizing the text: The code applies a series of regular expression substitutions to normalize the text. For example, it replaces contractions like \"won't\" with \"will not\", \"can't\" with \"can not\",\n",
        "  #  and so on. It also removes unnecessary characters and replaces commas with spaces.\n",
        "  s=re.sub(' ',' ',s)\n",
        "  s=re.sub(r\"won\\'t\",\"will not\", s)\n",
        "  s=re.sub(r\"can't\",\"can not\", s)\n",
        "  s=re.sub(r'\\,',' ',s)\n",
        "  s=re.sub(r\"n\\'t\",\" not\", s)\n",
        "  s=re.sub(r\"\\'re\",\" are\", s)\n",
        "  s=re.sub(r\"\\'s\",\" is\", s)\n",
        "  s=re.sub(r\"\\'d\",\" would\", s)\n",
        "  s=re.sub(r\"\\'ll\",\" will\", s)\n",
        "  s=re.sub(r\"\\'t\",\" not\", s)\n",
        "  s=re.sub(r\"\\'ve\",\" have\", s)\n",
        "  s=re.sub(r\"\\'m\",\" am\", s)\n",
        "  s=re.sub(r'[^\\w\\s]','', s)   #remove white spaces\n",
        "\n",
        "  # Removing stopwords: The code tokenizes the normalized text into words using the word_tokenize() function from NLTK. It then removes common English stopwords using a list comprehension and the stopwords.words('english')\n",
        "  #  function from NLTK. The resulting list is stored in new_text.\n",
        "  stop_words = stopwords.words('english')\n",
        "  words = word_tokenize(str(s))  #tokenize the s (document's words)\n",
        "\n",
        "  new_text = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "\n",
        "  key = \"doc_\" + str(doc_no)\n",
        "\n",
        "print(\"new_text:\",new_text)"
      ],
      "metadata": {
        "id": "v10rD9wmgtLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565d37ca-d27a-44f5-80dd-f33a55154e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_text: ['Remarks', 'Foreign', 'Policy', 'National', 'Press', 'Club', 'Washington', 'Thank', 'opportunity', 'speak', 'thank', 'Center', 'National', 'Interest', 'honoring', 'invitation', 'would', 'like', 'talk', 'today', 'develop', 'new', 'foreign', 'policy', 'direction', 'country', 'one', 'replaces', 'randomness', 'purpose', 'ideology', 'strategy', 'chaos', 'peace', 'time', 'shake', 'rust', 'America', 'foreign', 'policy', 'time', 'invite', 'new', 'voices', 'new', 'visions', 'fold', 'direction', 'outline', 'today', 'also', 'return', 'us', 'timeless', 'principle', 'foreign', 'policy', 'always', 'put', 'interests', 'American', 'people', 'American', 'security', 'else', 'foundation', 'every', 'decision', 'make', 'America', 'First', 'major', 'overriding', 'theme', 'administration', 'chart', 'path', 'forward', 'must', 'first', 'briefly', 'look', 'back', 'lot', 'proud', '1940s', 'saved', 'world', 'Greatest', 'Generation', 'beat', 'back', 'Nazis', 'Japanese', 'Imperialists', 'saved', 'world', 'time', 'totalitarian', 'Communism', 'Cold', 'War', 'lasted', 'decades', 'Democrats', 'Republicans', 'working', 'together', 'got', 'Mr', 'Gorbachev', 'heed', 'words', 'President', 'Reagan', 'said', 'tear', 'wall', 'History', 'forget', 'Unfortunately', 'Cold', 'War', 'foreign', 'policy', 'veered', 'badly', 'course', 'failed', 'develop', 'new', 'vision', 'new', 'time', 'fact', 'time', 'went', 'foreign', 'policy', 'began', 'make', 'less', 'less', 'sense', 'Logic', 'replaced', 'foolishness', 'arrogance', 'led', 'one', 'foreign', 'policy', 'disaster', 'another', 'went', 'mistakes', 'Iraq', 'Egypt', 'Libya', 'President', 'Obama', 'line', 'sand', 'Syria', 'actions', 'helped', 'throw', 'region', 'chaos', 'gave', 'ISIS', 'space', 'needs', 'grow', 'prosper', 'began', 'dangerous', 'idea', 'could', 'make', 'Western', 'democracies', 'countries', 'experience', 'interest', 'becoming', 'Western', 'Democracy', 'tore', 'institutions', 'surprised', 'unleashed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Stemming: The code initializes a PorterStemmer object and applies stemming to each word in new_text using a for loop. The stemmed words are stored in the stemmed list."
      ],
      "metadata": {
        "id": "Iip6HpU9Q9Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "stemmed = []\n"
      ],
      "metadata": {
        "id": "Qox8VmZyQqUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "for i in new_text:\n",
        "  stemmed.append(ps.stem(i))\n",
        "\n",
        "print(\"stemmed:\",stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm4SAhm1RD6i",
        "outputId": "30da59c1-6a57-42a1-e7ec-c7e207d35deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stemmed: ['remark', 'foreign', 'polici', 'nation', 'press', 'club', 'washington', 'thank', 'opportun', 'speak', 'thank', 'center', 'nation', 'interest', 'honor', 'invit', 'would', 'like', 'talk', 'today', 'develop', 'new', 'foreign', 'polici', 'direct', 'countri', 'one', 'replac', 'random', 'purpos', 'ideolog', 'strategi', 'chao', 'peac', 'time', 'shake', 'rust', 'america', 'foreign', 'polici', 'time', 'invit', 'new', 'voic', 'new', 'vision', 'fold', 'direct', 'outlin', 'today', 'also', 'return', 'us', 'timeless', 'principl', 'foreign', 'polici', 'alway', 'put', 'interest', 'american', 'peopl', 'american', 'secur', 'els', 'foundat', 'everi', 'decis', 'make', 'america', 'first', 'major', 'overrid', 'theme', 'administr', 'chart', 'path', 'forward', 'must', 'first', 'briefli', 'look', 'back', 'lot', 'proud', '1940', 'save', 'world', 'greatest', 'gener', 'beat', 'back', 'nazi', 'japanes', 'imperialist', 'save', 'world', 'time', 'totalitarian', 'commun', 'cold', 'war', 'last', 'decad', 'democrat', 'republican', 'work', 'togeth', 'got', 'mr', 'gorbachev', 'heed', 'word', 'presid', 'reagan', 'said', 'tear', 'wall', 'histori', 'forget', 'unfortun', 'cold', 'war', 'foreign', 'polici', 'veer', 'badli', 'cours', 'fail', 'develop', 'new', 'vision', 'new', 'time', 'fact', 'time', 'went', 'foreign', 'polici', 'began', 'make', 'less', 'less', 'sens', 'logic', 'replac', 'foolish', 'arrog', 'led', 'one', 'foreign', 'polici', 'disast', 'anoth', 'went', 'mistak', 'iraq', 'egypt', 'libya', 'presid', 'obama', 'line', 'sand', 'syria', 'action', 'help', 'throw', 'region', 'chao', 'gave', 'isi', 'space', 'need', 'grow', 'prosper', 'began', 'danger', 'idea', 'could', 'make', 'western', 'democraci', 'countri', 'experi', 'interest', 'becom', 'western', 'democraci', 'tore', 'institut', 'surpris', 'unleash']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating positional index posting list: The code creates a temporary dictionary temp_dict to store the positional index for each term in the document. It assigns a number to each word to identify its position and adds it to the corresponding key in temp_dict."
      ],
      "metadata": {
        "id": "hX4kvSkoRe53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict=dict()\n",
        "a=0"
      ],
      "metadata": {
        "id": "iK6aCrhARScY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in stemmed:\n",
        "  #assign numbers to each word to identify the position\n",
        "  key=x\n",
        "  temp_dict.setdefault(key,[])\n",
        "  temp_dict[key].append(a)\n",
        "  a+=1\n",
        "\n",
        "temp_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M1rxZ5URuj0",
        "outputId": "50e7ad8c-3750-4af1-8010-399822ffdea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'remark': [0],\n",
              " 'foreign': [1, 22, 38, 55, 123, 137, 150],\n",
              " 'polici': [2, 23, 39, 56, 124, 138, 151],\n",
              " 'nation': [3, 12],\n",
              " 'press': [4],\n",
              " 'club': [5],\n",
              " 'washington': [6],\n",
              " 'thank': [7, 10],\n",
              " 'opportun': [8],\n",
              " 'speak': [9],\n",
              " 'center': [11],\n",
              " 'interest': [13, 59, 184],\n",
              " 'honor': [14],\n",
              " 'invit': [15, 41],\n",
              " 'would': [16],\n",
              " 'like': [17],\n",
              " 'talk': [18],\n",
              " 'today': [19, 49],\n",
              " 'develop': [20, 129],\n",
              " 'new': [21, 42, 44, 130, 132],\n",
              " 'direct': [24, 47],\n",
              " 'countri': [25, 182],\n",
              " 'one': [26, 149],\n",
              " 'replac': [27, 145],\n",
              " 'random': [28],\n",
              " 'purpos': [29],\n",
              " 'ideolog': [30],\n",
              " 'strategi': [31],\n",
              " 'chao': [32, 168],\n",
              " 'peac': [33],\n",
              " 'time': [34, 40, 97, 133, 135],\n",
              " 'shake': [35],\n",
              " 'rust': [36],\n",
              " 'america': [37, 69],\n",
              " 'voic': [43],\n",
              " 'vision': [45, 131],\n",
              " 'fold': [46],\n",
              " 'outlin': [48],\n",
              " 'also': [50],\n",
              " 'return': [51],\n",
              " 'us': [52],\n",
              " 'timeless': [53],\n",
              " 'principl': [54],\n",
              " 'alway': [57],\n",
              " 'put': [58],\n",
              " 'american': [60, 62],\n",
              " 'peopl': [61],\n",
              " 'secur': [63],\n",
              " 'els': [64],\n",
              " 'foundat': [65],\n",
              " 'everi': [66],\n",
              " 'decis': [67],\n",
              " 'make': [68, 140, 179],\n",
              " 'first': [70, 79],\n",
              " 'major': [71],\n",
              " 'overrid': [72],\n",
              " 'theme': [73],\n",
              " 'administr': [74],\n",
              " 'chart': [75],\n",
              " 'path': [76],\n",
              " 'forward': [77],\n",
              " 'must': [78],\n",
              " 'briefli': [80],\n",
              " 'look': [81],\n",
              " 'back': [82, 91],\n",
              " 'lot': [83],\n",
              " 'proud': [84],\n",
              " '1940': [85],\n",
              " 'save': [86, 95],\n",
              " 'world': [87, 96],\n",
              " 'greatest': [88],\n",
              " 'gener': [89],\n",
              " 'beat': [90],\n",
              " 'nazi': [92],\n",
              " 'japanes': [93],\n",
              " 'imperialist': [94],\n",
              " 'totalitarian': [98],\n",
              " 'commun': [99],\n",
              " 'cold': [100, 121],\n",
              " 'war': [101, 122],\n",
              " 'last': [102],\n",
              " 'decad': [103],\n",
              " 'democrat': [104],\n",
              " 'republican': [105],\n",
              " 'work': [106],\n",
              " 'togeth': [107],\n",
              " 'got': [108],\n",
              " 'mr': [109],\n",
              " 'gorbachev': [110],\n",
              " 'heed': [111],\n",
              " 'word': [112],\n",
              " 'presid': [113, 159],\n",
              " 'reagan': [114],\n",
              " 'said': [115],\n",
              " 'tear': [116],\n",
              " 'wall': [117],\n",
              " 'histori': [118],\n",
              " 'forget': [119],\n",
              " 'unfortun': [120],\n",
              " 'veer': [125],\n",
              " 'badli': [126],\n",
              " 'cours': [127],\n",
              " 'fail': [128],\n",
              " 'fact': [134],\n",
              " 'went': [136, 154],\n",
              " 'began': [139, 175],\n",
              " 'less': [141, 142],\n",
              " 'sens': [143],\n",
              " 'logic': [144],\n",
              " 'foolish': [146],\n",
              " 'arrog': [147],\n",
              " 'led': [148],\n",
              " 'disast': [152],\n",
              " 'anoth': [153],\n",
              " 'mistak': [155],\n",
              " 'iraq': [156],\n",
              " 'egypt': [157],\n",
              " 'libya': [158],\n",
              " 'obama': [160],\n",
              " 'line': [161],\n",
              " 'sand': [162],\n",
              " 'syria': [163],\n",
              " 'action': [164],\n",
              " 'help': [165],\n",
              " 'throw': [166],\n",
              " 'region': [167],\n",
              " 'gave': [169],\n",
              " 'isi': [170],\n",
              " 'space': [171],\n",
              " 'need': [172],\n",
              " 'grow': [173],\n",
              " 'prosper': [174],\n",
              " 'danger': [176],\n",
              " 'idea': [177],\n",
              " 'could': [178],\n",
              " 'western': [180, 186],\n",
              " 'democraci': [181, 187],\n",
              " 'experi': [183],\n",
              " 'becom': [185],\n",
              " 'tore': [188],\n",
              " 'institut': [189],\n",
              " 'surpris': [190],\n",
              " 'unleash': [191]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary\n"
      ],
      "metadata": {
        "id": "G-mwlJ2NTFTI",
        "outputId": "2c492ea8-6e15-4247-9f06-d1dfc22f0658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating the inverted index: The code checks if each term in temp_dict already exists in the dictionary. If it does, it adds the positional index for the current document to the existing posting list. If the term is not present in the dictionary, it creates a new key and adds the positional index for the current document."
      ],
      "metadata": {
        "id": "Rs6dNW0xSlcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for word in temp_dict:\n",
        "\n",
        "  for doc_no in range(1,4):\n",
        "\n",
        "    with open(cwd+'/doc_'+str(doc_no)+'.txt','r') as file:\n",
        "\n",
        "      s=file.read().lower().replace('\\n',' ')\n",
        "\n",
        "      if word in s:\n",
        "        if word in dictionary:\n",
        "          dictionary[word][doc_no]=temp_dict.get(word)\n",
        "\n",
        "        else:\n",
        "          key=word\n",
        "          dictionary[key]={}\n",
        "          dictionary[word][doc_no]=temp_dict.get(word)"
      ],
      "metadata": {
        "id": "r_egDckXSrr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99S-iaVHahr3",
        "outputId": "c8a0a479-d8cb-4c3e-e734-a5ccc05ecc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'remark': {1: [0], 2: [0], 3: [0]},\n",
              " 'foreign': {3: [1, 22, 38, 55, 123, 137, 150]},\n",
              " 'nation': {3: [3, 12]},\n",
              " 'press': {3: [4]},\n",
              " 'club': {3: [5]},\n",
              " 'washington': {2: [6], 3: [6]},\n",
              " 'thank': {1: [7, 10], 2: [7, 10], 3: [7, 10]},\n",
              " 'opportun': {3: [8]},\n",
              " 'speak': {2: [9], 3: [9]},\n",
              " 'center': {3: [11]},\n",
              " 'interest': {3: [13, 59, 184]},\n",
              " 'honor': {1: [14], 2: [14], 3: [14]},\n",
              " 'invit': {3: [15, 41]},\n",
              " 'would': {2: [16], 3: [16]},\n",
              " 'like': {1: [17], 3: [17]},\n",
              " 'talk': {2: [18], 3: [18]},\n",
              " 'today': {2: [19, 49], 3: [19, 49]},\n",
              " 'develop': {3: [20, 129]},\n",
              " 'new': {1: [21, 42, 44, 130, 132],\n",
              "  2: [21, 42, 44, 130, 132],\n",
              "  3: [21, 42, 44, 130, 132]},\n",
              " 'direct': {3: [24, 47]},\n",
              " 'countri': {3: [25, 182]},\n",
              " 'one': {1: [26, 149], 2: [26, 149], 3: [26, 149]},\n",
              " 'replac': {3: [27, 145]},\n",
              " 'random': {3: [28]},\n",
              " 'purpos': {3: [29]},\n",
              " 'ideolog': {3: [30]},\n",
              " 'strategi': {2: [31]},\n",
              " 'chao': {3: [32, 168]},\n",
              " 'peac': {3: [33]},\n",
              " 'time': {1: [34, 40, 97, 133, 135],\n",
              "  2: [34, 40, 97, 133, 135],\n",
              "  3: [34, 40, 97, 133, 135]},\n",
              " 'shake': {3: [35]},\n",
              " 'rust': {3: [36]},\n",
              " 'america': {2: [37, 69], 3: [37, 69]},\n",
              " 'voic': {3: [43]},\n",
              " 'vision': {3: [45, 131]},\n",
              " 'fold': {3: [46]},\n",
              " 'outlin': {3: [48]},\n",
              " 'also': {3: [50]},\n",
              " 'return': {2: [51], 3: [51]},\n",
              " 'us': {1: [52], 2: [52], 3: [52]},\n",
              " 'timeless': {3: [53]},\n",
              " 'principl': {3: [54]},\n",
              " 'alway': {3: [57]},\n",
              " 'put': {3: [58]},\n",
              " 'american': {2: [60, 62], 3: [60, 62]},\n",
              " 'peopl': {1: [61], 2: [61], 3: [61]},\n",
              " 'secur': {3: [63]},\n",
              " 'els': {2: [64], 3: [64]},\n",
              " 'foundat': {3: [65]},\n",
              " 'decis': {3: [67]},\n",
              " 'make': {3: [68, 140, 179]},\n",
              " 'first': {3: [70, 79]},\n",
              " 'major': {3: [71]},\n",
              " 'overrid': {3: [72]},\n",
              " 'theme': {3: [73]},\n",
              " 'administr': {3: [74]},\n",
              " 'chart': {3: [75]},\n",
              " 'path': {3: [76]},\n",
              " 'forward': {3: [77]},\n",
              " 'must': {3: [78]},\n",
              " 'look': {3: [81]},\n",
              " 'back': {2: [82, 91], 3: [82, 91]},\n",
              " 'lot': {3: [83]},\n",
              " 'proud': {3: [84]},\n",
              " '1940': {3: [85]},\n",
              " 'save': {3: [86, 95]},\n",
              " 'world': {2: [87, 96], 3: [87, 96]},\n",
              " 'greatest': {3: [88]},\n",
              " 'gener': {3: [89]},\n",
              " 'beat': {1: [90], 3: [90]},\n",
              " 'nazi': {3: [92]},\n",
              " 'japanes': {3: [93]},\n",
              " 'imperialist': {3: [94]},\n",
              " 'totalitarian': {3: [98]},\n",
              " 'commun': {3: [99]},\n",
              " 'cold': {3: [100, 121]},\n",
              " 'war': {2: [101, 122], 3: [101, 122]},\n",
              " 'last': {1: [102], 3: [102]},\n",
              " 'decad': {3: [103]},\n",
              " 'democrat': {3: [104]},\n",
              " 'republican': {3: [105]},\n",
              " 'work': {1: [106], 3: [106]},\n",
              " 'togeth': {3: [107]},\n",
              " 'got': {3: [108]},\n",
              " 'mr': {3: [109]},\n",
              " 'gorbachev': {3: [110]},\n",
              " 'heed': {3: [111]},\n",
              " 'word': {3: [112]},\n",
              " 'presid': {1: [113, 159], 3: [113, 159]},\n",
              " 'reagan': {3: [114]},\n",
              " 'said': {3: [115]},\n",
              " 'tear': {3: [116]},\n",
              " 'wall': {3: [117]},\n",
              " 'forget': {3: [119]},\n",
              " 'unfortun': {3: [120]},\n",
              " 'veer': {3: [125]},\n",
              " 'cours': {3: [127]},\n",
              " 'fail': {3: [128]},\n",
              " 'fact': {3: [134]},\n",
              " 'went': {1: [136, 154], 3: [136, 154]},\n",
              " 'began': {3: [139, 175]},\n",
              " 'less': {3: [141, 142]},\n",
              " 'sens': {3: [143]},\n",
              " 'logic': {3: [144]},\n",
              " 'foolish': {3: [146]},\n",
              " 'arrog': {3: [147]},\n",
              " 'led': {3: [148]},\n",
              " 'disast': {2: [152], 3: [152]},\n",
              " 'anoth': {3: [153]},\n",
              " 'mistak': {3: [155]},\n",
              " 'iraq': {3: [156]},\n",
              " 'egypt': {3: [157]},\n",
              " 'libya': {3: [158]},\n",
              " 'obama': {3: [160]},\n",
              " 'line': {3: [161]},\n",
              " 'sand': {1: [162], 3: [162]},\n",
              " 'syria': {3: [163]},\n",
              " 'action': {2: [164], 3: [164]},\n",
              " 'help': {3: [165]},\n",
              " 'throw': {3: [166]},\n",
              " 'region': {3: [167]},\n",
              " 'gave': {3: [169]},\n",
              " 'isi': {1: [170], 2: [170], 3: [170]},\n",
              " 'space': {3: [171]},\n",
              " 'need': {3: [172]},\n",
              " 'grow': {3: [173]},\n",
              " 'prosper': {3: [174]},\n",
              " 'danger': {2: [176], 3: [176]},\n",
              " 'idea': {3: [177]},\n",
              " 'could': {3: [178]},\n",
              " 'western': {3: [180, 186]},\n",
              " 'democraci': {3: [181, 187]},\n",
              " 'experi': {3: [183]},\n",
              " 'becom': {3: [185]},\n",
              " 'tore': {3: [188]},\n",
              " 'institut': {3: [189]},\n",
              " 'surpris': {3: [190]},\n",
              " 'unleash': {3: [191]}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stop_words)\n",
        "print(words)"
      ],
      "metadata": {
        "id": "MUu3qM_ZjgiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp_dict)"
      ],
      "metadata": {
        "id": "LOiIg7gshCXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udTxssAThEdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m1uY-px-ii4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UmBXYjYi62E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}