{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFUhB8PSZkG",
        "outputId": "3f9eb693-9794-4173-b418-41ebb4d6e9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#commented out IPython magic to ensure Python compatibility\n",
        "#changing the current directory to this below path\n",
        "%cd /content/drive/MyDrive/IRWA_lab/inverted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V04gh7Y1SvF4",
        "outputId": "2e9829c6-1465-4578-d82f-f10affb141cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA_lab/inverted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cwd=os.getcwd()\n"
      ],
      "metadata": {
        "id": "gF_2IvtDTH8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "awNHa_eobuJD",
        "outputId": "0030e326-ac19-441f-cd6a-b9c8eba6e3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IRWA_lab/inverted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question a)"
      ],
      "metadata": {
        "id": "BXH1cFN_4d-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The os.listdir() function is used to retrieve a list of files present in the current directory (cwd).\n",
        "#The list of files is stored in the fileList variable.\n",
        "fileList=os.listdir(cwd)\n",
        "print(fileList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzkmK-wwTLul",
        "outputId": "eca892f1-9e8a-4d95-9c80-fb5fc67f9ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Doc1.txt', 'Doc2.txt', 'Doc3.txt', 'Doc4.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/IRWA_lab/inverted/Doc1.txt\",\"r\") as d1:\n",
        "  print(d1.read().split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZV5jYw4TTQU",
        "outputId": "f7d6836f-33d1-4564-ff86-ad0a19a4a884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['breakthrough', 'drug', 'for', 'schizophrenia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wordDict variable is initialized as an empty dictionary.\n",
        "#This dictionary will store the inverted index,\n",
        "#where each term will be a key and the corresponding value will be a list of documents in which the term appears.\n",
        "wordDict=dict()\n"
      ],
      "metadata": {
        "id": "h6z21j85Tns-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the inverted index: The code then iterates through each file in the fileList.\n",
        "\n",
        "a. For each file, it opens the file using the open() function, reading the contents of the file.\n",
        "\n",
        "b. The contents of the file are converted to lowercase using the .lower() method, and then split into individual words using the .split() method. This creates a list of words present in the file.\n",
        "\n",
        "c. The code then iterates through each word in the list of words.\n",
        "\n",
        "d. For each word, it checks if it is already present in the wordDict dictionary.\n",
        "\n",
        "If the word is not present in wordDict, it adds the word as a key and initializes the corresponding value as a list containing the current file.\n",
        "If the word is already present in wordDict, it appends the current file to the existing list of files associated with that word."
      ],
      "metadata": {
        "id": "jz-alq304bja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in fileList:\n",
        "  with open(\"/content/drive/MyDrive/IRWA_lab/inverted/\"+file,\"r\") as f:\n",
        "    words=f.read().lower().split()\n",
        "    #print(words)\n",
        "\n",
        "    for word in  words:\n",
        "      if word not in wordDict:\n",
        "        wordDict[word]=[file]\n",
        "      else:\n",
        "        wordDict[word]+=[file]\n",
        "print(wordDict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhD9MNijWBh5",
        "outputId": "cb5ea180-505b-403d-863e-8e2a376777d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'breakthrough': ['Doc1.txt'], 'drug': ['Doc1.txt', 'Doc2.txt'], 'for': ['Doc1.txt', 'Doc3.txt', 'Doc4.txt'], 'schizophrenia': ['Doc1.txt', 'Doc2.txt', 'Doc3.txt', 'Doc4.txt'], 'new': ['Doc2.txt', 'Doc3.txt', 'Doc4.txt'], 'approach': ['Doc3.txt'], 'treatment': ['Doc3.txt'], 'of': ['Doc3.txt'], 'hopes': ['Doc4.txt'], 'patients': ['Doc4.txt']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the inverted index: After building the inverted index,\n",
        "the code prints the wordDict dictionary,\n",
        "which represents the inverted index.\n",
        "It displays each term as a key and the corresponding list of documents as the value."
      ],
      "metadata": {
        "id": "jEKED7cy4YB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the invertedIndex() function: The code defines a function named invertedIndex(), which encapsulates the process of building the inverted index.\n",
        "\n",
        "a. Within the function, a new wordDict dictionary is created.\n",
        "\n",
        "b. The code then performs the same steps as described earlier to build the inverted index.\n",
        "\n",
        "c. Finally, the function returns the wordDict dictionary representing the inverted index."
      ],
      "metadata": {
        "id": "LWDEkRNE4VsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invertedIndex():\n",
        "  wordDict=dict()\n",
        "\n",
        "  for file in fileList:\n",
        "    with open(cwd+\"/\"+file,\"r\") as f:\n",
        "      words=f.read().lower().split()\n",
        "\n",
        "      for word in words:\n",
        "        if word not in wordDict:\n",
        "          wordDict[word]=[file]\n",
        "        else:\n",
        "          wordDict[word]+=[file]\n",
        "  return wordDict"
      ],
      "metadata": {
        "id": "QCfWplh_Xv5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invertedIndex()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPRDc5pGgchS",
        "outputId": "ea760bcc-c1e0-4cd9-90f5-cef28530029f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'breakthrough': ['Doc1.txt'],\n",
              " 'drug': ['Doc1.txt', 'Doc2.txt'],\n",
              " 'for': ['Doc1.txt', 'Doc3.txt', 'Doc4.txt'],\n",
              " 'schizophrenia': ['Doc1.txt', 'Doc2.txt', 'Doc3.txt', 'Doc4.txt'],\n",
              " 'new': ['Doc2.txt', 'Doc3.txt', 'Doc4.txt'],\n",
              " 'approach': ['Doc3.txt'],\n",
              " 'treatment': ['Doc3.txt'],\n",
              " 'of': ['Doc3.txt'],\n",
              " 'hopes': ['Doc4.txt'],\n",
              " 'patients': ['Doc4.txt']}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L=[10,20,30,40,100,200,400]\n",
        "\n",
        "L+[1,2,3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5FdxVYMgmKp",
        "outputId": "9c1cce3d-8902-4029-a537-a9549769c059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 20, 30, 40, 100, 200, 400, 1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(L)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k4zsr5_g7Fv",
        "outputId": "43f65484-ec6d-4024-fa8d-3ce8d6e45a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10, 20, 30, 40, 100, 200, 400}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a={1,2,3,4,5}\n",
        "b={3,4,5,6,8}\n",
        "\n",
        "a.intersection(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAcEoF_rg9wg",
        "outputId": "38ffe467-b06c-45a6-d7f1-97e85663dc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3, 4, 5}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question b\n",
        "Part 1) schizophrenia AND drug"
      ],
      "metadata": {
        "id": "cIU-Y3hE4MTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AND_op function: This function takes in two lists, list1 and list2, and returns the intersection of these two lists as a set. In other words,it returns the common elements between the two lists."
      ],
      "metadata": {
        "id": "Dhu9eW-94JN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AND_op(list1,list2):\n",
        "  return set(list1).intersection(set(list2))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ld3mqy9MhgUD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the inverted index: The code initializes the IndexDict variable with the inverted index generated by the invertedIndex() function. The inverted index is a dictionary where each term is associated with a list of documents in which it appears."
      ],
      "metadata": {
        "id": "IFUeAmQ74D8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IndexDict=invertedIndex()"
      ],
      "metadata": {
        "id": "anivBwxZzuA1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting lists for specific keys: The code loops through each key in IndexDict and ,\n",
        "checks if the key matches 'schizophrenia' or 'drug'. If a match is found, it assigns the corresponding value (list of documents) to List1 or List2, respectively."
      ],
      "metadata": {
        "id": "cQvCChej37k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key in IndexDict:\n",
        "  if key=='schizophrenia':\n",
        "    List1=IndexDict[key]\n",
        "  if key=='drug':\n",
        "    List2=IndexDict[key]\n",
        "\n",
        "print(\"List1\",List1)\n",
        "print(\"List2\",List2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5t8pCnDhoiB",
        "outputId": "d0548db9-6577-456f-9dcf-8fb6287e13b6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List1 ['Doc1.txt', 'Doc2.txt', 'Doc3.txt', 'Doc4.txt']\n",
            "List2 ['Doc1.txt', 'Doc2.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"(schizophrenia AND drug) result: \",AND_op(List1,List2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt0iGpYu0vaB",
        "outputId": "c45f4ec0-b8b8-4bfa-a778-61f14fe5df08"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(schizophrenia AND drug) result:  {'Doc1.txt', 'Doc2.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part2) for AND NOT(drug OR approach)"
      ],
      "metadata": {
        "id": "RaYKQRnV3xrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = AND_op(IndexDict.get('for', []), set(fileList) - set(IndexDict.get('drug', []) + IndexDict.get('approach', [])))\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_ECoHTe300b",
        "outputId": "4eeb7cc0-164b-4cf3-b2b8-d415e0d5cd17"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Doc4.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading NLTK(Natural Language Toolkit) resources**"
      ],
      "metadata": {
        "id": "ISZwkWKk1Lqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code downloads required NLTK resources by using the nltk.download() function with the arguments 'punkt' and 'stopwords'. These resources include tokenizers and a list of stopwords for the English language."
      ],
      "metadata": {
        "id": "sYqQ8G_F1L25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize  import  word_tokenize\n"
      ],
      "metadata": {
        "id": "hRRcG_Suhq0c"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quote=\"Pythoners are very intelligent and work  vey pythonly and\""
      ],
      "metadata": {
        "id": "Slf4s_tZhuP7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing NLTK libraries**: The code imports necessary libraries from the Natural Language Toolkit (NLTK), including stopwords and word_tokenize. These libraries provide functionalities for dealing with stopwords (common words to be ignored) and tokenizing text into individual words."
      ],
      "metadata": {
        "id": "8EweTGZu5OBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZUSorYphvqn",
        "outputId": "3f56b570-2d27-4f24-e136-5c0547a67622"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizing the quote**: The code tokenizes the string quote into a list of words using the word_tokenize() function from NLTK. This step splits the quote into individual words."
      ],
      "metadata": {
        "id": "_u8OwCgB5Vlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words=word_tokenize(quote)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV5lXRAGhxIF",
        "outputId": "a35fb90e-2a78-4271-f38f-7855dffe8819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pythoners',\n",
              " 'are',\n",
              " 'very',\n",
              " 'intelligent',\n",
              " 'and',\n",
              " 'work',\n",
              " 'vey',\n",
              " 'pythonly',\n",
              " 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining stopwords**: The code sets up a set of stopwords using the stopwords.words(\"english\") function from NLTK. Stopwords are common words that are often removed from text during natural language processing tasks because they generally do not carry much meaning."
      ],
      "metadata": {
        "id": "vDXtGibd5hZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words(\"english\"))\n",
        "\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQC2cg-jhy2L",
        "outputId": "c0ec4df3-cb81-4c7c-b3b1-f7bca095f868"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'having', 'only', 'him', 'didn', 'into', 'hadn', 'nor', 'doesn', 'between', 'did', 'from', \"it's\", 'some', 'up', 'o', 'yours', 'for', 'them', 'there', \"hasn't\", 'when', \"hadn't\", 'ma', \"you'll\", 'all', 'above', 'its', 'over', 'so', 'what', 'both', 'should', 'needn', 'through', 'am', 'themselves', 'until', 'here', 'aren', 'she', 'as', 'can', 'ain', 'wasn', 'whom', 'just', 'doing', \"mightn't\", \"isn't\", 'own', 'haven', 'down', 'out', 'now', 'is', 'most', 'at', \"couldn't\", 'an', \"haven't\", 'but', 'our', 'it', 'won', 'himself', 'same', 'theirs', 'mustn', 'by', 'itself', 'be', 'where', 'while', \"wasn't\", 'these', 'which', 'then', 's', 'if', 'very', 'mightn', 'yourselves', 're', 'me', 'my', 'because', 'further', 'once', 'i', 'who', 'hers', \"don't\", \"you'd\", 'a', 't', 'y', 'yourself', 'll', 'isn', 'ours', 'or', \"aren't\", 'to', 'in', 'shan', 'on', \"weren't\", 'do', \"she's\", 'again', 'other', 'off', 'herself', \"that'll\", 'her', \"should've\", 'after', 'such', \"you've\", 'any', 'those', 'd', \"mustn't\", 'under', 'before', 'no', 'not', \"needn't\", \"shan't\", 'being', 'of', 'their', 'than', 'weren', \"wouldn't\", 'been', 'too', 'will', 'don', 'we', 'about', \"won't\", 'does', 'more', 'few', 'has', 'why', 'wouldn', 'ourselves', 'how', 'have', 'they', 'against', 'had', 'this', 'during', 'the', \"you're\", 'couldn', \"doesn't\", 'are', 'm', 'that', \"shouldn't\", 'myself', 'and', 'were', 've', \"didn't\", 'you', 'shouldn', 'each', 'was', 'with', 'he', 'his', 'below', 'your', 'hasn'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filtering out stopwords**: The code creates an empty list called filtered_list and iterates over each word in the words list. It checks if the lowercase version of the word is present in the stop_words set. If not, the word is appended to the filtered_list. This step removes stopwords from the words list."
      ],
      "metadata": {
        "id": "toT9Wuwc5mbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list=[]\n",
        "for word in words:\n",
        "  if  word.casefold()  not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "print(filtered_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zivk1m7Lh0aE",
        "outputId": "5e2900b1-6eb9-42ee-a819-f17b8dfbda70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pythoners', 'intelligent', 'work', 'vey', 'pythonly']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[word for word in words if word.casefold() not in stop_words]"
      ],
      "metadata": {
        "id": "anGQfIR6h2Eb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding new words  to  the stop  words**"
      ],
      "metadata": {
        "id": "vHf-9Th56H9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filtering out extended stopwords**: The code creates an empty list called filtered_list_new and iterates over each word in the words list. It checks if the lowercase version of the word is present in the stop_words_new list. If not, the word is appended to the filtered_list_new. This step removes both original stopwords and the additional words from the words list."
      ],
      "metadata": {
        "id": "fBs4X6jC6bDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "stop_words_new=list(stop_words)\n",
        "stop_words_new.extend([\"intelligent\",\"work\"])\n",
        "\n",
        "filtered_list_new=[]\n",
        "for word in words:\n",
        "  if word.lower() not in stop_words_new:\n",
        "    filtered_list_new.append(word)\n",
        "print(filtered_list_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqBoEnglh3zc",
        "outputId": "22f89e25-b1a5-4369-8189-2a011ddc0b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pythoners', 'vey', 'pythonly']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Porter Stemmer Algorithm**"
      ],
      "metadata": {
        "id": "i_DHvEdK7BrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "p9pax4p5h98G"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quote=\"Pythoners  are very intelligent  and work very pythonly and now they are pyth\""
      ],
      "metadata": {
        "id": "SahD8ajWiBcp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()"
      ],
      "metadata": {
        "id": "ZMceqOzC7ZHJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=word_tokenize(quote)\n",
        "\n",
        "stemmed_words=[stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zfuE2sQiC3b",
        "outputId": "210bca78-6485-4cb9-bb2f-3d06321ec6d2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['python', 'are', 'veri', 'intellig', 'and', 'work', 'veri', 'pythonli', 'and', 'now', 'they', 'are', 'pyth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMxOIqGSiEjo"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7i48vvAouAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}